# Binary Cross-Entropy
The log loss, or binary cross entropy, is given by the following function.

$$\text{BCE}=-y\log{\left(\sigma(z)\right)}-(1-y)\log{\left(1-\sigma(z)\right)}$$

This programme shows how the log loss, aka Binary Cross Entropy (BCE), vary with different probabilities, $\sigma(z)$, for a given label $y$.

